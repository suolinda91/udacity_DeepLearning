\part{Convolutional Neural Networks}
\chapter{Introduction to CNNs}
\href{https://www.youtube.com/watch?v=-dLdeL6BAZs&t=1s&ab_channel=Udacity}{Youtube} \newline

A CNN is a neural network developed specifically for image and video processing. CNNs are used to automate many tasks, for example:

\begin{itemize}
    \item Image classification
    \item Object recognition
    \item Anomaly detection
    \item Image captioning
\end{itemize}
... and many others. They are widely used across many industries, including medicine, banking, manufacturing, insurance, real-estate, transportation (self-driving cars), and social networks.\newline

CNNs are arguably the main technology responsible for the Artificial Intelligence renaissance we are witnessing today, with billion of dollars in revenue generated by their application.\newline

We are very excited for you to be here with us and to learn about this invaluable technology!


\section{Course Overview}

\begin{itemize}
    \item Introduction to CNNs and basic concepts

\begin{itemize}
        \item Use Multi-Layer Perceptrons (MLPs) for image classification
        \item Understand the limitations of MLPs for images and how CNNs overcome them
        \item Learn basic concepts of CNNs and what makes them so powerful for image tasks
\end{itemize}

    \item CNNs in more depth

\begin{itemize}
        \item Learn all the basic layers that make up a CNN
        \item Put all the basic layers together to build a CNN from scratch
        \item Classify images using CNNs
        \item Use various methods to improve CNN performance
        \item Export models for production
\end{itemize}

    \item Transfer learning

\begin{itemize}
        \item Understand key innovative CNN architectures
        \item Implement transfer learning using a pre-trained network to classify different sets of images
        \item Fine-tune a pre-trained network on a new dataset
\end{itemize}

    \item Autoencoders

\begin{itemize}
        \item Explain the functionality of autoencoders for data compression, image denoising, and dimensionality reduction
        \item Build a simple autoencoder out of linear layers to perform anomaly detection
        \item Build CNN autoencoders to perform anomaly detection and image denoising
\end{itemize}

    \item Object detection and segmentation

\begin{itemize}
        \item Describe object detection, object localization, and image segmentation.
        \item Train and evaluate a one-stage object detection model to detect multiple objects in an image.
        \item Train and evaluate a semantic segmentation model to classify every pixel of an image.
\end{itemize}

\end{itemize}


\section{Prerequisites}

\subsection{Who Should Take This Course}

This course is intended for a student who is at least somewhat familiar with the basic concepts of elementary neural networks, and has good experience with Python programming.

\subsection{What You Should Already Know}

\subsubsection{Python}

\begin{itemize}
    \item Variables
    \item Loops
    \item Conditionals
    \item Functions
    \item \href{https://realpython.com/python3-object-oriented-programming/}{\textbf{Object-Oriented Programming, Classes}}
\end{itemize}
Experience with the Python scientific stack (NumPy, Matplotlib...) is going to be useful.

For the class we will be extensively using \href{https://tacc.github.io/CSC2017Institute/docs/day1/jupyter.html}{\textbf{Jupyter Notebooks}}.

\subsubsection{Machine Learning}

\begin{itemize}
    \item \href{https://machinelearningmastery.com/gradient-descent-for-machine-learning/}{\textbf{Loss function and gradient descent}}
    \item Train / validation / test split
    \item \href{https://machinelearningmastery.com/neural-networks-crash-course/}{\textbf{Neural Networks}}: We will recap these basic concepts, but some previous understanding of these concepts is required:

\begin{itemize}
        \item Perceptrons and Multi-Layer Perceptrons (MLP)
        \item Activations and functions (ReLU, softmaxâ€¦)
        \item Training a neural network
        \item Overfitting and underfitting
        \item Forward pass, backpropagation
        \item Regularization and \href{https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/}{\textbf{DropOut}}
\end{itemize}

\end{itemize}

\subsubsection{PyTorch}

We will briefly review all these concepts, but some previous familiarity with them will be helpful:

\begin{itemize}
    \item Datasets and dataloaders
    \item Common loss functions
    \item Training, validation, and test loops
    \item Multi-Layer Perceptrons in PyTorch
\end{itemize}

\section{Business Stakeholders}
\href{https://www.youtube.com/watch?v=JrCeIxzb2Fs&ab_channel=Udacity}{Youtube} \newline

If you use CNNs to power a real product in a real-world setting, you are going to interact with several different profiles:

\begin{itemize}
    \item Data Scientist / Machine Learning Engineer: Responsible for developing the ML pipeline and the model, as well as performing all the relevant analytics - for example on data quality and performance measurements.
    \item Data Engineers: Responsible for the data ingestion pipelines, the quality of the data that the DS/MLE receive, and for provisioning the right data at inference time.
    \item Software Engineers: Responsible for the production environment, both front-end and back-end, as well as for many pieces of the MLOps infrastructure. Involve them from the beginning to make sure that the model you are producing can fit into the production environment.
    \item DevOps Engineers: Help in handling the infrastructure, including training servers, various MLOps tools, and other infrastructure needed to train and deploy a model.
    \item Product Managers: Define the right problem to solve, exploit the knowledge of the customers, and define quantifiable deliverables and success criteria for the project. The PM also helps in keeping the project on time and on budget.
    \item Customers: Consumer of the product; we should always consider the customers' and users' perspectives for every decision that we make.
\end{itemize}

\section{History of CNNs}
\href{https://www.youtube.com/watch?v=1J6SM_3FoY4&ab_channel=Udacity}{Youtube} \newline

A brief history of CNNs:

\begin{itemize}
    \item \href{https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon}{\textbf{Perceptron (1958)}}: A one-neuron primitive neural network capable of classifying linearly-separable datasets.
    \item \href{https://en.wikipedia.org/wiki/Neocognitron\#:~:text=The\%20neocognitron\%20is\%20a\%20hierarchical,inspiration\%20for\%20convolutional\%20neural\%20networks.}{\textbf{Neocognitron (1980)}}: A neural network using two types of mechanisms that are the basis of modern CNNs: convolution and pooling.
    \item \href{https://en.wikipedia.org/wiki/Backpropagation\#History}{\textbf{Backpropagation (1986)}}: Allows training of neural networks end to end based on data.
    \item \href{https://en.wikipedia.org/wiki/Multilayer_perceptron}{\textbf{Multi-Layer Perceptron (1986)}}: The first proper neural network in the modern sense, theoretically capable of modeling any function.
    \item \href{http://yann.lecun.com/exdb/lenet/}{\textbf{LeNet-5 (1998)}}: The first proper Convolutional Neural Network with practical application, used to model handwritten digits obtaining an accuracy of almost 99\%. This seminal work sparked a new renaissance of work on Convolutional Neural Networks for image recognition.
    \item \href{https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/}{\textbf{ImageNet (2010-2017)}}: A competition with the goal of modeling with the largest possible accuracy a large dataset of more than 1 million natural images classified into 1000 classes.
\end{itemize}
The ImageNet competition spawned several innovations, starting with AlexNet, the first CNN to win the contest. AlexNet won in 2012 by a huge margin, when the runners-up were still trying to use classical computer vision methods. After 2012, every team in the competition used Convolutional Neural Networks.

Since then, the performance on the ImageNet dataset has continued improving at a very fast pace. Most of the architectures from around 2012 - 2020 were based exclusively on Convolutional Neural Networks. After that, a different class of neural network called Transformers started to conquer the top of the rankings. These days the most accurate architectures such as ViT and CoAtNet use a mix of CNN and Transformer elements. Many of these architectures also use additional data.

CNNs however are still the workhorses for real-world applications of neural networks on images, because they can achieve very good performances while requiring orders of magnitude less data and compute than pure Transformers.

\section{Tools \& Environment}
\href{https://www.youtube.com/watch?v=qV-o9eVOWTs&ab_channel=Udacity}{Youtube} \newline
All the software that you need to complete the exercises and develop your final project is pre-installed in the Udacity workspaces here in your classroom.\newline

If you want to run something locally, every exercise and the project come with a file (\verb|requirements.txt|) which contains all the dependencies that you need to install. You can install them in your Python environment by issuing the command: \verb|pip install -r requirements.txt|.\newline

In many cases you will need a GPU to complete the exercises and the project with reasonable execution times. The Udacity workspace we provide in your classroom comes with a GPU that you can opt to use. If instead you want to run locally, you will need to install all the relevant software needed for your GPU to work with PyTorch. You can find some instructions \href{https://pytorch.org/get-started/locally/}{\textbf{here}}.\newline

\section{Project Preview}
\href{https://www.youtube.com/watch?v=4R5eOA7hCuA&t=3s&ab_channel=Udacity}{Youtube} \newline

n the final project, you will classify landmarks in images uploaded to a social network, in order to localize the images. \newline

You will be given the dataset containing the images and their label (the landmark contained in the image). You will train two CNNs: one that you will design from scratch, and a standard one that you will fine-tune on the dataset. You will also build a little app, powered by your best model.
