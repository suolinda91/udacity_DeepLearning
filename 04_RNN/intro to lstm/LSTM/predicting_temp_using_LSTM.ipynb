{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Temperature Time Series with LSTM Using PyTorch\n",
    "\n",
    "### Introduction\n",
    "Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that is commonly used for sequence modeling, particularly for processing time-series data. Unlike traditional RNNs, LSTMs have a memory cell that allows them to selectively remember or forget information over time, which makes them particularly useful for long-term dependencies.\n",
    "\n",
    "In this tutorial, we'll use Pytorch to build an LSTM model that can predict a time-series based on previous data. We'll use numpy and pandas to preprocess the data.\n",
    "\n",
    "## Step 1: Import Libraries\n",
    "We'll start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Data\n",
    "For this tutorial, we'll use a sample dataset that contains temperature readings for a single sensor over time. We'll load the dataset into a pandas DataFrame and preprocess it so that it can be fed into our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a pandas DataFrame\n",
    "df = pd.read_csv('../data/temperature.csv')\n",
    "\n",
    "# Convert the 'datetime' column to a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the 'datetime' column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample the data to hourly intervals and fill missing values with the previous value\n",
    "df = df.resample('H').ffill()\n",
    "\n",
    "# Normalize the data\n",
    "df = (df - df.mean()) / df.std()\n",
    "\n",
    "# Convert the DataFrame to a numpy array\n",
    "data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split Data\n",
    "\n",
    "Next, we'll split the data into training and testing sets. We'll use the first 70% of the data for training and the remaining 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(data) * 0.7)\n",
    "train_data, test_data = data[:train_size], data[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Data Sequences\n",
    "Before we can train our LSTM model, we need to create sequences of data that the model can learn from. We'll create sequences of length 24 (one day), and we'll use a sliding window approach to create overlapping sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences of data\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences for training and testing data\n",
    "seq_length = 24\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create LSTM Model\n",
    "Now, we'll create our LSTM model using Pytorch. Our model will have one LSTM layer with 32 hidden units and one fully connected output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ``__init__`` method, we define an LSTM layer with hidden_size hidden units and a fully connected output layer with output_size output units. In the forward method, we pass the input `x` through the LSTM layer, take the output of the last time step, and pass it through the fully connected output layer.\n",
    "\n",
    "### Step 6: Instantiate Model and Define Loss Function and Optimizer\n",
    "Now, we'll instantiate our LSTM model, define our loss function (mean squared error), and define our optimizer (Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "model = LSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Model\n",
    "Next, we'll train our LSTM model on the training data. We'll use a batch size of 32 and train for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to Pytorch tensors\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "num_epochs = 25\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the training data\n",
    "    perm = torch.randperm(X_train.shape[0])\n",
    "    X_train = X_train[perm]\n",
    "    y_train = y_train[perm]\n",
    "\n",
    "    # Loop over batches\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        # Get batch\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss for this epoch\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate the Model\n",
    "Finally, we'll evaluate our LSTM model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "\n",
    "# Calculate the test loss\n",
    "test_loss = criterion(y_pred, y_test)\n",
    "print('Test Loss: {:.4f}'.format(test_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert Pytorch tensors to numpy arrays\n",
    "y_test = y_test.numpy()\n",
    "y_pred = y_pred.numpy()\n",
    "\n",
    "# Plot predicted vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test[:500], label='Actual')\n",
    "plt.plot(y_pred[:500], label='Predicted')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.title('LSTM Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
