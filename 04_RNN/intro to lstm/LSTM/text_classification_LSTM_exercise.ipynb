{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using LSTM\n",
    "\n",
    "In this coding exercise, you will create a simple LSTM model using PyTorch to perform text classification on a dataset of short phrases. Your task is to fill in the missing parts of the code marked with `# TODO`.\n",
    "\n",
    "You need to:\n",
    "\n",
    "- Create a vocabulary to represent words as indices.\n",
    "- Tokenize, encode, and pad the phrases.\n",
    "- Convert the phrases and categories to PyTorch tensors.\n",
    "- Instantiate the LSTM model with the vocabulary size, embedding dimensions, hidden dimensions, and output dimensions.\n",
    "- Define the loss function and optimizer.\n",
    "- Train the model for a number of epochs.\n",
    "- Test the model on new phrases and print the category predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases (textual data) and their category labels (0 for sports, 1 for technology, 2 for food)\n",
    "# Note: this data is extremely less for realistically training an LSTM model. Feel free to use\n",
    "# a relevant data source or create your own dummy data for this exercise.\n",
    "phrases = [\"great goal scored\", \"amazing touchdown\", \"new phone release\", \"latest laptop model\", \"tasty pizza\", \"delicious burger\"]\n",
    "categories = [0, 0, 1, 1, 2, 2]\n",
    "\n",
    "# TODO: Create a vocabulary to represent words as indices\n",
    "\n",
    "# TODO: Tokenize, encode, and pad phrases\n",
    "\n",
    "# TODO: Convert phrases and categories to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "class PhraseClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(PhraseClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        logits = self.fc(hidden.squeeze(0))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate model and define loss and optimizer\n",
    "\n",
    "# TODO: Train the model for a number of epochs\n",
    "\n",
    "# TODO: Test the model on new phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
