{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator and Generator implementation\n",
    "\n",
    "In this notebook, you will implement the generator and discriminator models. These models will be use in the last exercise of this lesson to train your first GAN network! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "The discriminator network is going to be a pretty typical linear classifier. To make this network a universal function approximator, we'll need at least one hidden layer, and these hidden layers should have one key attribute:\n",
    "> All hidden layers will have a [Leaky ReLu](https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU) activation function applied to their outputs.\n",
    "\n",
    "<img src='assets/gan_network.png' width=70% />\n",
    "\n",
    "#### Leaky ReLu\n",
    "\n",
    "We should use a leaky ReLU to allow gradients to flow backwards through the layer unimpeded. A leaky ReLU is like a normal ReLU, except that there is a small non-zero output for negative input values.\n",
    "\n",
    "<img src='assets/leaky_relu.png' width=40% />\n",
    "\n",
    "#### Output\n",
    "\n",
    "We'll also take the approach of using a more numerically stable loss function on the outputs. Recall that we want the discriminator to output a value 0-1 indicating whether an image is _real or fake_. \n",
    "> We will ultimately use [BCEWithLogitsLoss](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss), which combines a `sigmoid` activation function **and** binary cross entropy loss in one function. \n",
    "\n",
    "So, our final output layer should not have any activation function applied to it.\n",
    "\n",
    "#### Structure\n",
    "\n",
    "The discriminator takes a high dimensional input (for example, an image) and outputs a single score value. Linear layers in the discriminator should have a number of neurons such that the dimensions of their output is smaller than the dimension of their input.\n",
    "\n",
    "### First exercise\n",
    "\n",
    "Implement a discriminator network. Your network should:\n",
    "* use fully connected layer and leaky relu\n",
    "* output a single logit\n",
    "* take a image as input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator model:\n",
    "    args: \n",
    "    - input_dim: dimension of the input data. For example, for a 28 by 28 grayscale image, the input size is 784\n",
    "    - hidden_dim: a parameter that controls the dimensions of the hidden layers. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #### \n",
    "        # IMPLEMENT HERE\n",
    "        ####\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #### \n",
    "        # IMPLEMENT HERE\n",
    "        ####\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a 28x28 grayscale image flattened, the input dim is 784\n",
    "input_dim = 784\n",
    "hidden_dim = 256\n",
    "\n",
    "discriminator = Discriminator(input_dim, hidden_dim)\n",
    "tests.check_discriminator(discriminator, input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    "The generator network will be almost exactly the same as the discriminator network, except that we're applying a [tanh activation function](https://pytorch.org/docs/stable/nn.html#tanh) to our output layer.\n",
    "\n",
    "#### tanh Output\n",
    "The generator has been found to perform the best with $tanh$ for the generator output, which scales the output to be between -1 and 1, instead of 0 and 1. \n",
    "\n",
    "<img src='assets/tanh_fn.png' width=40% />\n",
    "\n",
    "Recall that we also want these outputs to be comparable to the *real* input pixel values, which are read in as normalized values between 0 and 1. \n",
    "> So, we'll also have to **scale our real input images to have pixel values between -1 and 1** when we train the discriminator. \n",
    "\n",
    "## Second Exercise\n",
    "Implement a generator network. Your network should:\n",
    "* use fully connected, leaky relu and tanh layers\n",
    "* take a latent as input\n",
    "* output a vector (we will later reshape it as an image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int, output_size: int):\n",
    "        super(Generator, self).__init__()\n",
    "        #### \n",
    "        # IMPLEMENT HERE\n",
    "        ####\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #### \n",
    "        # IMPLEMENT HERE\n",
    "        ####\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "hidden_dim = 256\n",
    "output_dim = 784\n",
    "\n",
    "generator = Generator(latent_dim, hidden_dim, output_dim)\n",
    "tests.check_generator(generator, latent_dim, output_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
